% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/linked_urls.R
\name{linked_urls}
\alias{linked_urls}
\title{Linked Sites}
\usage{
linked_urls(x, delay = 0.2, max_depth = 5, excludesites = NULL, ...)
}
\arguments{
\item{x}{The root url as a character string, or a html session.}

\item{delay}{number of seconds to delay between http requests.}

\item{max_depth}{Starting with the root url (level 0) follow links upto}

\item{excludesites}{(default is \code{NULL})
\code{max_depth} "clicks".}

\item{...}{additional arguments (not yet used)}
}
\description{
Crawl a website, building a site map, and reporting all internal and external
links found.
}
\details{
The \code{max_depth} controls the number of links to follow.  The root url is
level 0 and all the hrefs found on that page are level 1.  Each href on a
level 1 page are labeled level 2.  These labels and processing of the pages
will continue through level \code{max_depth}.  You could think of
\code{max_depth} as the number of mouse clicks needed to navagate a web page
by a human in a graphical web browser to the noted url or file.
}
